{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f1b990-ae33-4471-b11d-fed1d44fd8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with gini and max_depth=None: 0.4918032786885246\n",
      "Decision Tree visualization saved as: decision_tree_gini_depth_None.png\n",
      "Accuracy with gini and max_depth=3: 0.5409836065573771\n",
      "Decision Tree visualization saved as: decision_tree_gini_depth_3.png\n",
      "Accuracy with entropy and max_depth=None: 0.4918032786885246\n",
      "Decision Tree visualization saved as: decision_tree_entropy_depth_None.png\n",
      "\n",
      "Comparison of Decision Tree Accuracies:\n",
      "\n",
      "- Decision Tree with Gini Index and no max depth (max_depth=None) has an accuracy of 49.18%. This model might be overfitting as it is allowed to grow without restrictions.\n",
      "- Decision Tree with Gini Index and max depth set to 3 (max_depth=3) shows improved accuracy at 54.10%. Limiting the depth likely helped in reducing overfitting, resulting in better performance on the test set.\n",
      "- Decision Tree with Entropy and no max depth (max_depth=None) also has an accuracy of 49.18%, indicating that simply changing the criterion to Entropy without limiting depth does not significantly affect performance.\n",
      "\n",
      "Overall, the Decision Tree with Gini Index and a max depth of 3 provides the best accuracy among the three, suggesting that controlling the depth of the tree can be beneficial for preventing overfitting and improving model performance on unseen data.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "\n",
    "df = pd.read_csv('heart-disease-dataset2.csv')\n",
    "\n",
    "df = df.replace('?', np.nan).apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "\n",
    "X = df.drop(columns=['result'])  \n",
    "y = df['result']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def decision_tree_analysis(criterion='gini', max_depth=None):\n",
    "    dt = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth, random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy with {criterion} and max_depth={max_depth}: {accuracy}')\n",
    "    \n",
    "    dot_data = export_graphviz(dt, out_file=None, feature_names=X.columns, class_names=True, filled=True, rounded=True)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "    image_path = f'decision_tree_{criterion}_depth_{max_depth}.png'\n",
    "    graph.write_png(image_path)\n",
    "    print(f'Decision Tree visualization saved as: {image_path}')\n",
    "\n",
    "\n",
    "decision_tree_analysis(criterion='gini')\n",
    "\n",
    "\n",
    "decision_tree_analysis(criterion='gini', max_depth=3)\n",
    "\n",
    "\n",
    "decision_tree_analysis(criterion='entropy')\n",
    "\n",
    "\n",
    "print(\"\\nComparison of Decision Tree Accuracies:\\n\")\n",
    "print(\"- Decision Tree with Gini Index and no max depth (max_depth=None) has an accuracy of 49.18%. This model might be overfitting as it is allowed to grow without restrictions.\")\n",
    "print(\"- Decision Tree with Gini Index and max depth set to 3 (max_depth=3) shows improved accuracy at 54.10%. Limiting the depth likely helped in reducing overfitting, resulting in better performance on the test set.\")\n",
    "print(\"- Decision Tree with Entropy and no max depth (max_depth=None) also has an accuracy of 49.18%, indicating that simply changing the criterion to Entropy without limiting depth does not significantly affect performance.\")\n",
    "print(\"\\nOverall, the Decision Tree with Gini Index and a max depth of 3 provides the best accuracy among the three, suggesting that controlling the depth of the tree can be beneficial for preventing overfitting and improving model performance on unseen data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfae46f-9b09-46a3-a558-f2a4707d3271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca73197-a980-4093-8373-796f0d63ca8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7230863e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
